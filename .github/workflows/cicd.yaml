name: CICD Pipeline

on:
  push:
    branches:
      - master   # ðŸ‘ˆ Change if your default branch is 'main'

jobs:
  model-deployment:
    runs-on: ubuntu-latest

    steps:
    # ======================================================
    # âœ… STEP 1 â€” CHECKOUT REPO
    # ======================================================
    - name: Checkout code
      uses: actions/checkout@v3
      with:
        fetch-depth: 0

    # ======================================================
    # âœ… STEP 2 â€” SETUP PYTHON
    # ======================================================
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    # ======================================================
    # âœ… STEP 3 â€” CACHE DEPENDENCIES
    # ======================================================
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Upgrade pip and install dependencies
      run: |
        python -m pip install --upgrade pip setuptools wheel
        pip install -r requirements.txt

    # ======================================================
    # ðŸŸ¡ STEP 4 â€” CHECK PIPELINE CHANGES (DVC)
    # ======================================================
    - name: Check for pipeline changes
      id: check_pipeline
      run: |
        if [ -z "${{ github.event.before }}" ]; then
          echo "No base commit detected. Running pipeline by default."
          echo "run_dvc=true" >> $GITHUB_ENV
          exit 0
        fi

        git fetch origin ${{ github.ref }}
        CHANGED_FILES=$(git diff --name-only ${{ github.event.before }} ${{ github.sha }})
        echo "Changed files:"
        echo "$CHANGED_FILES"

        if echo "$CHANGED_FILES" | grep -E '(^dvc\.yaml$|^dvc\.lock$|^params\.yaml$|^data/|^src/)'; then
          echo "Relevant pipeline changes detected âœ…"
          echo "run_dvc=true" >> $GITHUB_ENV
        else
          echo "No relevant pipeline changes detected â©"
          echo "run_dvc=false" >> $GITHUB_ENV
        fi

    # ======================================================
    # âœ… STEP 5 â€” RUN DVC PIPELINE (IF NEEDED)
    # ======================================================
    - name: Run DVC Pipeline
      if: env.run_dvc == 'true'
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_DEFAULT_REGION: eu-north-1
        MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
      run: |
        if dvc status -c | grep -q "Data and pipelines are up to date."; then
          echo "No DVC changes detected. Skipping repro."
        else
          dvc repro
        fi

    - name: Push DVC-tracked data to remote
      if: env.run_dvc == 'true'
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_DEFAULT_REGION: eu-north-1
      run: dvc push

    # ======================================================
    # âœ… STEP 6 â€” REGISTER MODEL IN MLFLOW (FIXED)
    # ======================================================
    - name: Register model in MLflow
      if: env.run_dvc == 'true'
      env:
        MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_DEFAULT_REGION: eu-north-1
      run: python src/model/register_model.py

    # ======================================================
    # âœ… STEP 7 â€” INSTALL TEST DEPENDENCIES & RUN TESTS
    # ======================================================
    - name: Install test dependencies
      run: pip install pytest

    - name: Run model tests
      if: env.run_dvc == 'true'
      env:
        MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      run: |
        pytest scripts/test_model_loading.py
        pytest scripts/test_model_signature.py
        pytest scripts/test_model_accuracy.py

    # ======================================================
    # âœ… STEP 8 â€” LOGIN TO ECR
    # ======================================================
    - name: Login to AWS ECR
      run: |
        aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws ecr get-login-password --region eu-north-1 | docker login --username AWS --password-stdin 193311515551.dkr.ecr.eu-north-1.amazonaws.com

    # ======================================================
    # âœ… STEP 9 â€” BUILD DOCKER IMAGE (from ECR base)
    # ======================================================
    - name: Build Docker Image
      run: docker build -t reddit_chrome_plugin:latest .

    # ======================================================
    # âœ… STEP 10 â€” TAG AND PUSH TO ECR
    # ======================================================
    - name: Tag Docker Image
      run: docker tag reddit_chrome_plugin:latest 193311515551.dkr.ecr.eu-north-1.amazonaws.com/reddit_chrome_plugin:latest

    - name: Push Docker Image to ECR
      run: docker push 193311515551.dkr.ecr.eu-north-1.amazonaws.com/reddit_chrome_plugin:latest
